{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import explainability.utils\n",
    "from config.dataset import FastTextModelDataset\n",
    "from config.preprocess import clean_and_tokenize_df\n",
    "from pytorch_model import FastTextModel, FastTextModule\n",
    "from tokenizer import NGramTokenizer\n",
    "\n",
    "# Automatic discovery : if MLFlow has been launched before Jupyter/VSCode\n",
    "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
    "    print(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "else:\n",
    "    print(\"MLflow was not automatically discovered, a tracking URI must be provided manually.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"fasttext-pytorch\"\n",
    "version = 8\n",
    "module = mlflow.pytorch.load_model(model_uri=f\"models:/{model_name}/{version}\")\n",
    "model = module.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"fasttext\"\n",
    "version = 1\n",
    "fasttext = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.pth\")\n",
    "model.direct_bagging = False\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Rénovation bâtiments dont: électricité, plomberie, serrurerie, menuiserie\",\n",
    "    \"Gestion de portefeuille pour le compte de tiers et gestion de fonds d'investissement\",\n",
    "    \"L'acquisition, l'apport, la propriété, la mise en valeur, la transformation, la construction, l'aménagement, l'administration, la location\",\n",
    "    \"Saisie de documents et extraction de donnée pour le compte d'entreprises\",\n",
    "    \"L'investissement immobilier, l'achat et vente de biens immobiliers en qualité de marchand de Biens, la promotion immobilière, la gestion loc\",\n",
    "    \"La Société a pour objet en France et à l'étranger : - l'activité de conseil au profit de toute personne physique ou morale ; - l'enseignement et la formation de toutes matières en cours collectifs et particuliers à domicile ou dans des établissements scolaires\",\n",
    "]\n",
    "\n",
    "text = [\"Rénovation bâtiments dont: électricité, plomberie, serrurerie, menuiserie\"]\n",
    "topk = 4\n",
    "params = {\"additional_var\": [1] * len(text)}\n",
    "# params = {f\"feature_{i}\": x[1 + i][0].numpy().tolist() for i in range(len(x) - 1)}\n",
    "pred, confidence, all_scores, all_scores_letters = model.predict_and_explain(\n",
    "    text, params, top_k=topk\n",
    ")\n",
    "print(pred)\n",
    "print(confidence)\n",
    "explainability.explainability_viz.visualize_word_scores(all_scores, text, pred)\n",
    "explainability.explainability_viz.visualize_letter_scores(all_scores_letters, text, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "fasttext_times = []\n",
    "pytorch_times = []\n",
    "pytorch_explain_times = []\n",
    "for i in tqdm(range(1000)):\n",
    "    start = time.time()\n",
    "    _ = fasttext.predict(text)\n",
    "    end = time.time()\n",
    "    fasttext_times.append(end - start)\n",
    "    start = time.time()\n",
    "    _ = model.predict(text, params, explain=False)\n",
    "    end = time.time()\n",
    "    pytorch_times.append(end - start)\n",
    "    start = time.time()\n",
    "    _ = model.predict(text, params, explain=True)\n",
    "    end = time.time()\n",
    "    pytorch_explain_times.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FastText: {np.mean(fasttext_times)}\")\n",
    "print(f\"Pytorch: {np.mean(pytorch_times)}\")\n",
    "print(f\"Pytorch Explain: {np.mean(pytorch_explain_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"},\n",
    "    key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    ")\n",
    "df = (\n",
    "    pq.ParquetDataset(\n",
    "        \"projet-ape/extractions/20241027_sirene4.parquet\",\n",
    "        filesystem=fs,\n",
    "    )\n",
    "    .read_pandas()\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "df = df.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = clean_text_feature(df, text_feature=\"libelle\")\n",
    "df, _ = clean_and_tokenize_df(df)\n",
    "encoder = LabelEncoder()\n",
    "df[\"apet_finale\"] = encoder.fit_transform(df[\"apet_finale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"apet_finale\"\n",
    "text_feature = \"libelle\"\n",
    "categorical_features = [\"EVT\", \"CJ\", \"NAT\", \"TYP\", \"CRT\", \"SRF\"]\n",
    "features = [text_feature]\n",
    "if categorical_features is not None:\n",
    "    features += categorical_features\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[features],\n",
    "    df[y],\n",
    "    test_size=1 - 0.8,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values[:, 1:].astype(int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(X_train.values, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_epochs\": 1,\n",
    "    \"patience\": 3,\n",
    "    \"train_proportion\": 0.8,\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.004,\n",
    "    \"buckets\": 2000000,\n",
    "    \"dim\": 180,\n",
    "    \"minCount\": 1,\n",
    "    \"minn\": 3,\n",
    "    \"maxn\": 6,\n",
    "    \"wordNgrams\": 3,\n",
    "    \"sparse\": False,\n",
    "}\n",
    "\n",
    "max_epochs = params[\"max_epochs\"]\n",
    "patience = params[\"patience\"]\n",
    "train_proportion = params[\"train_proportion\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "lr = params[\"lr\"]\n",
    "buckets = params[\"buckets\"]\n",
    "embedding_dim = params[\"dim\"]\n",
    "min_count = params[\"minCount\"]\n",
    "min_n = params[\"minn\"]\n",
    "max_n = params[\"maxn\"]\n",
    "word_ngrams = params[\"wordNgrams\"]\n",
    "sparse = params[\"sparse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchFastText import torchFastText\n",
    "\n",
    "model = torchFastText(\n",
    "    num_buckets=buckets,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_classes=21,\n",
    "    min_count=min_count,\n",
    "    min_n=min_n,\n",
    "    max_n=max_n,\n",
    "    len_word_ngrams=word_ngrams,\n",
    ")\n",
    "\n",
    "model.build(df[\"libelle\"], df[[\"EVT\", \"CJ\", \"NAT\", \"TYP\", \"CRT\", \"SRF\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = X_train[text_feature].to_list()\n",
    "tokenizer = NGramTokenizer(min_count, min_n, max_n, buckets, word_ngrams, training_text)\n",
    "\n",
    "train_dataset = FastTextModelDataset(\n",
    "    categorical_variables=[\n",
    "        X_train[column].astype(int).to_list() for column in X_train[categorical_features]\n",
    "    ],\n",
    "    texts=training_text,\n",
    "    outputs=y_train.to_list(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "val_dataset = FastTextModelDataset(\n",
    "    categorical_variables=[\n",
    "        X_val[column].astype(int).to_list() for column in X_val[categorical_features]\n",
    "    ],\n",
    "    texts=X_val[text_feature].to_list(),\n",
    "    outputs=y_val.to_list(),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df[y].nunique()\n",
    "categorical_vocabulary_sizes = [np.max(X_train[feature]) + 1 for feature in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vocabulary_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CJ.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastTextModel(\n",
    "    tokenizer=tokenizer,\n",
    "    nace_encoder=encoder,\n",
    "    embedding_dim=embedding_dim,\n",
    "    vocab_size=buckets + tokenizer.get_nwords() + 1,\n",
    "    num_classes=num_classes,\n",
    "    categorical_vocabulary_sizes=categorical_vocabulary_sizes,\n",
    "    padding_idx=buckets + tokenizer.get_nwords(),\n",
    "    sparse=sparse,\n",
    "    direct_bagging=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x[0], x[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "if sparse:\n",
    "    optimizer = SGD\n",
    "else:\n",
    "    optimizer = Adam\n",
    "optimizer_params = {\"lr\": lr}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler_params = {\n",
    "    \"mode\": \"min\",\n",
    "    \"patience\": patience,\n",
    "}\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# Lightning module\n",
    "module = FastTextModule(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_params=optimizer_params,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_params=scheduler_params,\n",
    "    scheduler_interval=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.training_step(x, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
